 so I keep talking about this Silicon Valley ethos and I've got some examples of of what that means in terms of of setting Loosely internet on our political systems so it kills monkey is a thought experiment and Netflix did it said Imagine You release a bunch of monkeys in your server room and it's not unplugging stuff is your infrastructure going to be resilient is it going to be able to keep up with monkeys and plugging random and so this book says that Tech is the chaos monkeys of society like huh so what happens if I allow anybody to rent a room in their place oh nobody in Barcelona can afford to buy an apartment anymore sounds like you problem not a me problem and it feels kind of the same like you know open and I'll be like you know I'm gonna just realize this I don't know how this is going to impact the world they actually said that let's just test it out in the meantime this is how we did it and then a bunch of other people release it and then suddenly you can release it as the fourth guy who released it so it's not your fault you were trying to be chill and then you know everybody else oh there's no concept art anymore oh all the famous artists are being copied yeah oh  etc etc so this idea of the ways in which we release Technologies and and listen they're well-intentioned engineering solutions to perceived problems the problem is is that they often don't have any incentive structures to deal with what are the um worst case uses of this technology and how will this technology in many cases like Zuckerberg said he wanted to move fast and break things but breaking things like voting doesn't seem like something you'd want to do so the idea of of having the internet for voting for plebiscites should be great it should allow for more turnout and accessible elections for improved uh voter turnout assuming that's what we want and so these security and privacy concerns I mean long been the argument that if you wanted to really do e-voting you just put it with your Banks because your banks are the ones who have the closest relationship to you a lot of banks are now almost entirely digital and they verify identity and they could do security and background a lot better because they have money um literal money and that they have to protect that money it's the one thing they want to do um and so designing systems that prevent manipulation of ballots well while protecting privacy yeah I mean I don't know if we trust the banks enough if they have an interest in a political outcome right so that idea of firewalling um so yeah we've got examples Estonia is this digitally connected place that we keep referring to because it's been so on the Forefront of this stuff um Municipal elections in Nova Scotia Ontario increasing uh voter turnout and then this idea of allowing indigenous Nations to have access to the internet so they can that people can um can vote can participate um and I mean in the last provincial election it's still a problem of just getting voting stations on reserves that this has been a persistent problem that we still see to this day um that were were chronically because of infrastructure and capacity resources um training all the rest of it getting these into the sites where they are but these are largely exceptions and not the norm uh so when we think about digitally enabled politics we really need to think about the ways in which Tech promises solutions to problems but then might not actually deliver it becomes what what first is a bug then becomes a feature or the claimed feature never moves past the bug stage so I've been good to to stay off picking on Elon this one I just can't help next year will probably be 90 capable of autopilot like so 90 of miles could be on auto you know for sure Highway uh travel we're probably only a month away from having a autonomous driving baseball highways and for relatively simple roads like a model S and model X at this point I can drive autonomously with greater safety than a person right now is self-driving will be will Encompass essentially all remote driving and the 100 to 200 percent safer than a person by the FX talking for maybe 18 months from now I feel very confident predicting I'm I'm extremely confident of achieving a full autonomy uh and releasing it to the Tesla customer base uh next year when do you think Tesla will solve Level 4 FSD [Music] I mean it's looking quite likely that it will be next year [Music] um so the idea here is that in a democratic system when you have private actors they're able to make claims and the question is who's going to hold them to account especially when we've got all these problems with media that we've talked about before um I would also say on that I mean the grumpy old Geeks have been arguing this it's a podcast um they've been arguing this for a decade the problem isn't self-driving cars it's people it's the other people on the road if if it was all self-driving cars that would be fine the problem is is that there's people on the road and all the self-driving still has problems with I mean famously when Uber was testing it um had a problem it couldn't identify if someone crossing the road was a biker or pedestrian biker pedestrian biker pedestrian and while it was trying to figure that out it ran over them so the idea here is that just because we have technology doesn't mean that the application that technology is always going to result in outcomes we want um you know they just had a report come out of that that the auto drive has I think it's killed 17 people in the last four years I don't know if that's more or less though than regular cars right but at least with the regular cars we feel like we can hold someone accountable it's harder when you just say oh my software went wrong or right I didn't design that properly right so all systems then especially open systems are open to manipulation an example of this would be the idea of Wikipedia so making things democratic can provide you with the ability of anybody to make claims we're just not sure if we want anybody making claims 77 percent of all Wikipedia articles are written by one percent of its editors I saw one the other day there's some guy goes around he's like corrected like 40 000 times like the they're an expression because he's Vigilant about this expression sure it's great that we're all doing this and that people can dedicate those times having one percent of people control 77 percent of the Articles though sounds a lot like editorial control rather than democracy right um vandalism is usually repair quickly most users never see the effects um you know political covered commentators argue that the the coverage is affected by liberal by assure if your sources are liberal or it's going to reproduce that um the real dangerous part is New York Times has reported that U.S courts have over 100 judicial rulings that have replied on relied on the encyclopedia including taxes narcotics civil issues personal injury matrimony they rely on Wikipedia people have already been one lawyer already got censured for using chat GPT that made up a bunch of cases and so the idea here is that this is that like the benefits of an open system an open system produces information that we can all edit and vet and so this is like open source software and open source intelligence they're they're better systems because you have more eyes on them the problem of course is is the epistemic problems right so if we all have a certain assumption that things work a certain way it doesn't matter what field we're in um we can take politics we still use 1648 as the foundation of of sovereignty and that sovereignty is the best way to explain the International System blah blah blah blah um or the system in which it works but then that has a whole bunch of tacit biases like it just erases the way in which settlement involves massive displacement and genocide um and so those questions then become epistemically pushed out we have Paradigm debates where like which approach is best and we'll talk about that next week and then academic disciplining them itself so many sub-disciplines sub-journals there's journals of whatever studies now you can have um you know gamification looking at video game studies you can do pornography studies you can do whatever you want there's there's studies of everything which specializes um information listen we've got more scientists alive today than have ever existed in human history it's just the number of people so you're going to have extreme specialization which means that it's going to be harder and harder to have generalists be able to talk about things across disciplines which then reproduces the likelihood of epistemic bias right of of you all agreeing on something because everybody in your narrow discipline does without thinking about what another discipline is saying about that um and so of course we have Echo Chambers on the internet and so that's reinforced that they these are all examples of democratic information reinforcing non-democratic ways of being which is all back to the liberal democracy discussion is that we kind of need to enforce liberal democracy we have to have people who are advocating for those liberal values they don't develop organically there is always Force threat of force use of violence in order to reinforce the ideas that we use so um we have this idea then that different social groupings have different ways of conceptualizing what the good is or what we should be doing and so you can have false information that gets through these open systems and so that's misinformation or the intentional information that is disinformation we can still have this discussion we'll have it in class as just what was the reason for the Iraq War it is one of those situations where there's so many things overlapping on each other everybody's result tells us more about which one of those they're coming from than it does about the actual events right and so things like election interference and voting in elections it's not new both the U.S and the USSR tried to routinely interfere in each other's political processes Radio free America Cold War incentives threats manipulations Flyers drop Flyers about how how terrible it is with your leader in charge get a new leader um I won't I don't have any time to get into the Haiti stuff but Canada us and France intervened and it resulted in a democratically elected leader being ousted and we've had in the last couple years the assassination of um of the Haitian president um by a miami-based um dentist I I don't even know the the data's so bad in order to destabilize I don't know we don't have a new uh leader in place and so we've got these ways in which countries interfere in one another I'll leave it at that there's a lot a lot to do there um we have former colonies uh UK France Netherlands Spain that continually um have interests and continue to show interest in the outcomes of Elections Spain specifically in Catalonia um secessionist movements right you want to try to destabilize those movements and let them not in the case of Spain literally not have a referendum on whether or not they want to leave um make it illegal and then um everybody wants to interfere with the US so Iran China the Soviet Union Vietnam um the Nazis Israel everybody wants to interfere um with those because it it affects their their those States directly right so there's a vested interest in engaging in that um and so we don't know if there is a way to prevent foreign election interference it is cheaper than it's ever been and it's more easy than it's ever been and I'll bring in some examples in a bit the problem and why it's cheaper is because we have these monopolistic platforms which means that everybody actually is in the same place and so this is um I just did you stats counter the the extent to which Facebook is dominant social media and Google is dominant in search that means that if you're searching these things having information on those platforms means that that's where people are going to get information also we have massive consolidation of of most media platforms uh down the bottom there is is Canada's Consolidated media platforms um you know in 1983 in the US you had many in 2011 you had uh six I think we're down to four three four and even in Europe um there's basically one two three four five six seven that have have basically control of all those other so it reproduces that problem we saw with the video earlier um and so the idea of having a monopolistic control of media does reinforce the ways in which Bad actors can spread their messages at scale and scope that they could have in otherwise couldn't have otherwise um and so while we want to have democracy it's not clear there's nothing about Athenian democracy specifically because it relates to citizenship and then who is a citizen and who is not what information the citizens are supposed to have and should the information be Democratic or should it reinforce the idea that citizens and those only citizens should have a say in the outcome and so this becomes the problem about operations abroad to interfere I don't know did Tick Tock could be one big massive social disruption campaign put on by China into the U.S only because it's not reflected back into China if it was reflected back into China if it was a it's not WeChat it's it's not a platform that goes back into the country in which it came from and so that by definition means that it's going to have more influence elsewhere than at home and so this idea of using things like Wikileaks to spread information um you know Assange famously is an anarchist so he wants to intentionally sabotage the nation-states of the world and that makes him a threat to those nation states and it's not clear that anybody's going to defend you if you're a threat to All Nation States um and so I mean Nate silver the kind of he's the the famous political scientist who you know predicted um Obama's elections and then didn't do such a great job with Trump but he did say that that the idea of Russian interference from the Cambridge analytica data is is insignificant he said you know social media memes from Russia seem to have more impact than this Scandal that we said Facebook is responsible for it's like well how do we do this and so what what this means then is that in terms of Elections cyberspace elevates actors that wouldn't otherwise be able to to do what they can do so for example a traditional military force the U.S spends as much as the rest of the world combined clearly has what we would call hard power it has the capacity to do things with weapons and force in terms of soft power this is values and ideas the U.S has certainly declined in that that realm right it holding itself up as an example for the rest of the world has not been the last several I mean this goes back a while right um back to the Bush Administration of defunding or actively working against the United Nations it degrades the perception of the US and the eyes of others and so what happens then is that those others and this goes to what we'll talk about next week with Barrel power balancing um that cyber actors can magnify what what Joseph Nya Jr calls sharp power sharp power is the use of manipulative diplomatic policies by one country to influence and undermine the political system of another so you can do this through elections but you can do this by causing social unrest fomenting social unrest I've got some screen caps of um uh um stuff relating to uh Colin Kaepernick and the kneeling and the uh geolocation they forgot to turn off so it was they clearly says Russian actors are getting involved in supporting or antagonizing about um things like the Kaepernick um in the NFL the kneeling um as a responsive black lives matter we'll talk about it in a bit and so you don't actually need military force or moral persuasion you don't need hard or soft power if you can just interfere in others elections so you can use these regimes without fear of backlash and it gives um these this kind of asymmetry what's been called the Splinter net so um the open internet is is one form the closed internet um of uh China and a heavily regulated internet is another form and then the Russian internet which is actively interfering everywhere else and it's a clear crypto scams and theft and and crime all stemming from the ways in which that space is regulated means that the open system is more vulnerable than either of the other two and so this is the problem with cyber infrastructure is that 85 percent is in private hands and so states have to try to deal with a system that they don't entirely control so here's a discussion of the splinternet well well Andy was basically telling me was that everybody has to pitch in when it comes to cyber security Now what happens if the ongoing trade tensions lead to two internets three different internet sets of regulations and firms unable to cooperate cross-border I've been talking about the concept of three internets for a period of time now it's it's growing more defined more distinct that as regulatory environments split in their requirements and the Norms that they're trying to preserve that we're going to see a Chinese a European and a U.S and the rest of the world internet and what we're seeing over time is that that tension is not just developing between the United States and with China it's developing in those three Internets the recent French cyber security strategy didn't bother to put out an English translation and that tells us something about how the world is splitting up the regulatory burden of trying to ensure both I've heard Russia as the third one but EU makes sense too because it's the gdpr it has its own privacy regulations and a heavily regulated internet internet um and so the the danger of course is that we have different models we don't know about things like Tick Tock or businesses make money off of tick tock because they can advertise there it's a huge massive thing okay fine this is what um zuboff has called this kind of cycle of this technology on the internet what happens over and over again is the release of Technology um uh people get used to using the technology we all are on the I'm lecturing with the technology um and then we realize oh maybe we should have regulated this thing and so they might make some changes or not um but in the end they'll try to make you oh worry about that thing instead so we've been through multiple phases of this at this time uh all the cryptocurrency Bitcoin stuff we've been through this with web3 we're now going through it with AI or large language models every time we get somebody releasing a technology and the question is do we think that all those these systems are going to use them the same like a Chinese system that's already involved in regulating its populace now can automate that the European system can put in it already has heavy protections on overview and regulation of of AI and large language models and the Americans are like here you go just throw this stuff out there and see what happens so it's just this weird system why where we get this this idea of the experience then it also produces these very different experiences that you want to use a technology because it's new and interesting but over time it just degrades in its quality as it becomes more commercial or more regulated the easiest example is the um the cookies right so what was happening with cookies is that you were constantly being tracked and monitored and so finally they regulated them and said well you have to let people know they're being tracked and monitored so now on every stupid website we have to hit OK I accept cookies it's it's fundamentally useless it's a legal regulation that has taken something that was a problem and now has just made you constantly not even think about the problem and just click ok as if that that regulation produced a better outcome and so the problem is is that as these Technologies develop and emerge they become more and more habituated in the context in which they are and then reflect those values and interests so you know you'll have a platform that you just simply don't use anymore it's unusable because it doesn't do those things or the platform decides for let's do the case of Reddit we want to have um we've been around forever we've got a big user base all of these large language models are training off of Reddit data and red is not making any money so they're like well we're going to clamp down and we're going to make everybody use the official Reddit app which as I mentioned sucks um and in doing that they alienate and their entire user base and cause them to to get upset um but you understand they're a business they're trying to make money and so this is what's called The incidentification Thesis I don't like to use this guy too much because there's another Prof and then we're just kind of like echoing each other but you know this is fine and it comes from just a popular concept it's taking what zubov calls and she in her surveillance capitalism book talks about this dispossession cycle this way in which it takes your information and then increasingly the state and the business uses it against you um because kind of shittier what is the initiative insidification is a concept that was coined by the journalist and writer Cordy doctor back at the beginning and as you might have guessed from the word itself it describes the process by which websites platforms become shittier now his doctor describes it insidification is a three-step process Stage One locking the end users stage two lock in the business user stage three exploit them for instance doctor describes Amazon locked in young parents by selling Diapers at below cost lock them into such an extent that it destroyed divers.com after which Amazon could jack the price up past whatdiapers.com had been offering and it applies to social media too whether it's tick tock's Creator fund which is never grown in size or new incentives to create videos that are too long to be monetized on their competitor's plan I think Canada still doesn't have a Creator fund does it I I think we've been Ricky's walking we're behind the line where you piss people off but not so much that they leave so what's your favorite example of in shape what I don't care about that so this is just the idea that um we have to understand the political and social context in which social media is deployed and it's not uniform and it's always going to have these forms of resistance and the resistance doesn't have to be from below it can be from above too we would like more regulation I believe we need to age Gate apps right we've got enough data now that the harm and wellness of especially teenage girls on a lot of these apps um needs to have some type of of age gating on them so that we can at least say that if if we know the harms there we know who is subject there maybe not Target them with the same ads or distinguish but there just is no effort to regulate that and there's no effort to do that even though we know there's harm being caused